#!/bin/python

# Copyright 2017 Databricks, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# Script to generate TF graphs for DeepImageFeaturizer.
#
# Takes keras models in sparkdl.transformers.keras_applications and prepends reshaping from ImageSchema
# and model specific preprocessing.
# Produces tensor flow model files and a scala file containing scala wrappers for all the models.
#
# Input: sparkdl.transformers.keras_aplications.KERAS_APPLICATION_MODELS
#
# Output (all in the working directory):
#    1. model *.pb files (need to be uploaded to S3) .
#    2. generated scala model wrappers Models.scala.generated (needs to be moved over to appropriate scala folder)
#
from base64 import b64encode
from hashlib import sha256

import tensorflow as tf
import keras.backend as K

from sparkdl.graph import utils as tfx
from sparkdl.transformers import *
from sparkdl.transformers.keras_applications import *
from sparkdl.transformers.named_image import *

scala_template = """
  private[sparkdl] object %(name)s extends NamedImageModel {
    override val name = "%(name)s"
    override val height = %(height)d
    override val width = %(width)d
    override val graphInputNode = name + "_input"
    override val graphOutputNode = name + "_sparkdl_output__"

    override def graph: GraphDef = ModelFetcher.getFromWeb(
        "https://s3-us-west-2.amazonaws.com/spark-deep-learning-models/sparkdl-%(name)s_v%(version)d.pb",
        fileName = "sparkdl-inceptionV3_v%(version)d.pb",
        base64Hash = "%(base64)s"
    )
  }
"""


def gen_model(name, model, model_file, version=1, featurize=True):
    g = tf.Graph()
    with tf.Session(graph=g) as session:
        K.set_learning_phase(0)
        inTensor = tf.placeholder(dtype=tf.string, shape=[], name="%s_input" % name)
        decoded = tf.decode_raw(inTensor, tf.uint8)
        imageTensor = tf.to_float(
            tf.reshape(
                decoded,
                shape=[
                    1,
                    model.inputShape()[0],
                    model.inputShape()[1],
                    3]))
        m = model.model(preprocessed=model.preprocess(imageTensor), featurize=featurize)
        outTensor = tf.to_double(tf.reshape(m.output, [-1]), name="%s_sparkdl_output__" % name)
        gdef = tfx.strip_and_freeze_until([outTensor], session.graph, session, False)
    g2 = tf.Graph()
    with tf.Session(graph=g2) as session:
        tf.import_graph_def(gdef, name='')
        filename = "sparkdl-%s_v%d.pb" % (name, version)
        print 'writing out ', filename
        tf.train.write_graph(g2.as_graph_def(), logdir="./", name=filename, as_text=False)
        with open("./" + filename, "r") as f:
            h = sha256(f.read()).digest()
            base64_hash = b64encode(h)
            print 'h', base64_hash
    model_file.write(
        scala_template % {
            "name": name,
            "height": model.inputShape()[0],
            "width": model.inputShape()[1],
            "version": version,
            "base64": base64_hash})
    return g2


if __name__ == '__main__':
    filename = "Models.scala.__generated"
    print('generating', filename)
    with open(filename, "w") as f:
        f.write("\n".join([
            'package com.databricks.sparkdl',
            '',
            'import java.nio.file.Paths',
            'import org.tensorflow.framework.GraphDef',
            'import com.databricks.sparkdl.DeepImageFeaturizer.NamedImageModel',
            '/**',
            ' * File generated by sparkdl.utils.generate_app_models.',
            ' * Models defined in sparkdl.transformers.keras_applications.py',
            ' */',
            '',
            'object Models {',
            '',
            '  private[sparkdl] object TestNet extends NamedImageModel {',
            '  /**',
            '  * A simple test graph used for testing DeepImageFeaturizer',
            '  */',
            '    override val name = "_test"',
            '    override val height = 60',
            '    override val width = 40',
            '    override val graphInputNode = "input"',
            '    override val graphOutputNode = "sparkdl_output__"',
            '',
            '    override def graph: GraphDef = {',
            '      val file = getClass.getResource("/sparkdl/test_net.pb").getFile',
            '      ModelFetcher.importGraph(Paths.get(file), "jVCEKp1bV53eib8d8OKreTH4fHu/Ji5NHMOsgdVwbMg=")',
            '        .getOrElse {',
            '          throw new Exception(s""\"The hash of file $file did not match the expected value.""\".stripMargin)',
            '        }',
            '    }',
            '  }',
            ''
        ]))
        for name, modelConstructor in sorted(
                keras_applications.KERAS_APPLICATION_MODELS.items(), key=lambda x: x[0]):
            print 'generating model', name
            g = gen_model(name=name, model=modelConstructor(), model_file=f)
            print 'placeholders', [x for x in g._nodes_by_id.values() if x.type == 'Placeholder']
        f.write(
            "  val _supportedModels = Set[NamedImageModel](TestNet," +
            ",".join(
                keras_applications.KERAS_APPLICATION_MODELS.keys()) +
            ")\n")
        f.write("}\n")
        f.write("\n")
